<!-- SPDX-License-Identifier: zlib-acknowledgement -->
TODO: harvard in-text referencing
(Smith, 2020, p. 15).
(Jones, 2018, pp. 22-23).

- answered the question(s) with reasons
- articulated objections to reasons and responses to these
- specifically cite course material to support points being made
- cite external literature also?

Daily life continues to involve more technologies.
As a result, there are far-reaching societal impacts to consider 
when creating computer science ethical guidelines. 
Act utilitarianism focuses on acts that lead to the most overall good, 
while rule utilitarianism emphasises following rules that lead to the greatest good.
By considering leadership challenges relating to data obtainment and user security,
it can be seen that rule utilitarianism is more desirable.
It allows for the creation of guidelines that 
are both beneficial to society and simple for a governing body to implement.

Under rule utilitarianism, ethical guidelines for data retrieval can be made consistent.
This promotes societal confidence in the computer science profession, 
leading to a happier society.
Decisions made relating to data retrieval practices in technologies 
greatly impact user's rights.
Github copilot is an AI code completion tool that is trained on 
public code repositories (Github, 2023).
Considering act utilitarianism, it's permissable for technologies like this
to scrape as much user data as desired and use it for any purpose. 
These actions can be done regardless of user consent.
A justification for this could be that the resulting technology enables many 
programmers to create impactful software that they otherwise would've lacked 
the knowledge to do so.
Therefore, the rights of the user(s) who created the code
are supplanted by the prospect of enpowering many others. 
Proponents of this could argue that if consent was required, 
most likely no one would ever consent and the benefits of the technology could not be realised.
This echoes the self-defeatist criticism 
of act utilitarianism (Bennett 2015, p. 61).
Specifically, that in advancing technology accessibility as a means of improved happiness,
users of technologies lose trust in whether their data is protected.
This distrust can reduce technological adoption, decreasing overall happiness.
Following rule utilitarianism, it can be mandated that 
data collection should only occur with explicit user consent
and clear specification of how the data will be used.
Importantly, this protects data that predates any current rights framework.
Such protection goes beyond a value neutral approach to technology (Week 2 Lecture, pg. 10).
It's in line with Kranzberg's First Law, acknowledging that the future uses of technology, 
particularly AI, cannot be fully foreseen by its creators (Week 2 Lecture, pg. 14).
By requiring both consent and specified use, 
this system provides users with confidence in how their past, present, 
and future data will be handled. 
Critics may argue that this could reduce technological innovation and 
introduce biases due to limited data for training (Baeza-Yates 2018, pp. 57-58).
However, the long-term benefits of fostering a society that trusts tech companies 
outweigh these short-term costs.
Indeed, preserving trust aligns with Friedman's notion that
all computer technology should reflect human values to promote a better future (Friedman 1996, p. 22).
As a result, the consistency that rule utilitarianism offers compared to
act utilitarianism in relation to data privacy,
make it a more effective approach for developing ethical guidelines 
that promote societal happiness.

In the framework of rule utilitarianism, 
ethical guidelines concerning user security can be structured to 
protect individual rights at all times.
This provides society with a confidence of autonomy in the technology they use, 
enhancing happiness.
Security technologies introduce significant power dynamics between producers and consumers.
Intel SGX is a security technology that enables a machine's hardware to control what sofware it runs (Intel, n.d).
Under act utilitarianism, implementers of this technology could effectively render 
a user's machine unusable without any legal backing.
This would be done by blocking their hardware, so that any new software would not run on it.
A justification for this could be that rendering a 
malicious user offline would safeguard many more users who were potential victims.
Indeed, tech creators possess more specialised knowledge than legal bureaucrats.
In the current technological landscape where threats can emerge and spread quickly,
bypassing traditional legal processes could enable quicker and more informed decisions to be made.
As a result, that user's automony over their machine is forfeited for the general good.
This outcome is in violation of the ACM ethical guideline principal concerning people 
as stakeholders in computing.
Specifically, the imperative that all computing should protect each 
individual's right to autonomy (ACM, 2018 p. 4).
Having this as a possible outcome relies on society placing an immense amount 
of trust in technology manufacturers to act justly.
This dependence on tech could lead to widespread uneasiness in society.
Technology companies would have unchecked control over user's belongings, 
effectively placing them above the law. 
With the rise of smart devices, this control could extend to phones, appliances, cars and more (Sharma, 2020).
This illustrates how act utilitarianism can lead to immoral outcomes,
as discussed by Bennett (2015, p. 60).
It's immoral to seize one's property without proper litigation/warrant.
In contrast, rule utilitarianism would establish guidelines stating that 
security technologies restricting user freedom should only be implemented 
through legal channels, such as law enforcement. 
Furthermore, if no law exists to cover specific actions, the ethical imperative would be 
to create appropriate legislation before releasing such technology. 
Critics may argue that this approach could inadvertently 
allow the spread of malware and botnets, 
as malicious users wouldn't face immediate consequences 
like blacklisting, without established legal procedures. 
However, the benefits of a 
comprehensive legal framework in place before deploying 
potentially restrictive technologies far outweigh these concerns. 
The potential misuse of power by technology companies as seen by general society is reduced.
Any actions taken against users' devices will be subject 
to proper legal scrutiny and oversight.
This approach aligns with the broader goal of maximising societal happiness 
by providing clear, transparent rules that protect individual autonomy 
while still allowing for necessary security measures.
As rule utilitarnism strikes a balance between innovation and 
individual rights for security technologies, it's clear that's
more effective than act utilitarianism in constructing ethical guidelines that
maximise societal happiness.

In conclusion, ethical guidelines for the computer science profession 
should prioritise societal wellbeing. 
By examining leadership challenges in data privacy and user security, 
it is evident that rule utilitarianism better serves this goal compared to act utilitarianism. 
It does so by promoting consistent and straightforward rules that are easier to implement.


## Reference List
1. GitHub (2023). GitHub Copilot · Your AI pair programmer. 
   [online] Available at: https://github.com/features/copilot
   [Accessed 18 Sep. 2024].
2. Bennet, C. (2015): "What is this thing called ethics", second edition, Routledge.
3. Lecture Slides Week 2 - Ethics in Computing, AI Ethics, and Research Integrity, University of NSW, 2024.
4. Baeza-Yates, R., 2018. Bias on the web. Communications of the ACM, 61(6), pp.54-61. 
   Available at: http://dx.doi.org/10.1145/3209581 [Accessed 25 Sept. 2024].
5. Friedman, B., 1996. Value-Sensitive Design. interactions, 3(6), pp.16-23.
6. Intel. (n.d.). Intel® Software Guard Extensions (Intel® SGX). 
   [online] Available at: https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/software-guard-extensions.html
   [Accessed 18 Sep. 2024].
7. ACM, 2018. ACM Code of Ethics and Professional Conduct. New York: Association for Computing Machinery, Inc. DOI: 10.1145/3274591.
8. Sharma, L. (2020). The rise of internet of things and smart cities. In Towards Smart World (pp. 3-14). Chapman and Hall/CRC.
