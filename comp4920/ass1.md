<!-- SPDX-License-Identifier: zlib-acknowledgement -->
TODO: harvard in-text referencing
(Smith, 2020, p. 15).
(Jones, 2018, pp. 22-23).

- answered the question(s) with reasons
- articulated objections to reasons and responses to these
- specifically cite course material to support points being made
- cite external literature also?

TODO: email draft as google doc

Daily life continues to involve more technologies.
As a result, there are far-reaching societal impacts to consider 
when creating computer science ethical guidelines. 
Act utilitarianism focuses on acts that lead to the most overall good, 
while rule utilitarianism emphasises following rules that lead to the greatest good.
By considering leadership challenges relating to data obtainment and user security,
it can be seen that rule utilitarianism is more desirable.
It allows for the creation of guidelines that 
are both beneficial to society and simple for a governing body to implement.

Under rule utilitarianism, ethical guidelines for data retrieval can be made consistent.
This promotes societal confidence in the computer science profession, 
leading to a happier society.
Decisions made relating to data retrieval practices in technologies 
greatly impact user's rights.
Github copilot is an AI code completion tool that is trained on 
public code repositories (Github, 2023).
Considering act utilitarianism, it's permissable for technologies like this
to scrape as much user data as desired and use it for any purpose. 
These actions can be done regardless of user consent.
A justification for this could be that the resulting technology enables many 
programmers to create impactful software that they otherwise would've lacked 
the knowledge to do so.
Therefore, the rights of the user(s) who created the code
are supplanted by the prospect of enpowering many others. 
Proponents of this could argue that if consent was required, 
most likely no one would ever consent and the benefits of the technology could not be realised.
This echoes the self-defeatist criticism 
of act utilitarianism discussed by Bennett (2015, p. 61).
Specifically, that in advancing technology accessibility as a means of improved happiness,
users of technologies lose trust in whether their data is protected.
This distrust can reduce technological adoption, decreasing overall happiness.
Following rule utilitarianism, it can be mandated that 
data collection should only occur with explicit user consent
and clear specification of how the data will be used.
Importantly, this protects data that predates any current rights framework.
Such protection goes beyond a value neutral approach to technology (value).
It acknowledges Kranzberg's First Law that 
the future uses of technology, particularly AI, cannot be fully foreseen by its creators (kranz).
By requiring both consent and specified use, 
this system provides users with confidence in how their past, present, 
and future data will be handled. 
Critics may argue that this could reduce technological innovation and 
introduce biases due to limited data for training (bias ref).
However, the long-term benefits of fostering a society that trusts tech companies 
outweigh these short-term costs.
Indeed, preserving trust aligns with Friedman's notion that
all computer technology should reflect human values to promote a better future (Friedman).
As a result, the consistency that rule utilitarianism offers compared to
act utilitarianism in relation to data privacy,
make it a more effective approach for developing ethical guidelines 
that promote societal happiness.

In the framework of rule utilitarianism, 
ethical guidelines concerning user security can be structured to 
protect individual rights at all times.
This provides society with a confidence of autonomy in the technology they use, 
enhancing happiness.
Security technologies introduce significant power dynamics between producers and consumers.
Intel SGX is a security technology that utilises a hardware private key 
to allow the CPU to only run signed code (Intel, n.d).

TODO: use tech-agnostic terminology, i.e. pretend person knows nothing for private key

Under act utilitarianism, implementers of this technology could effectively render 
a user's machine unusable without any legal backing.
This would be done by blacklisting their private key, 
preventing them from running new software. 
A justification for this could be that rendering a 
malicious user offline would safeguard many more users who were potential victims.
Indeed, tech creators possess more specialised knowledge than legal bureaucrats.
In the current technological landscape where threats can emerge and spread quickly,
bypassing traditional legal processes could enable quicker and more informed decisions to be made.
As a result, that user's automony over their machine is forfeited for the general good.
This outcome is in violation of the ACM ethical guideline principal concerning people 
as stakeholders in computing.
Specifically, the imperative that all computing should protect each 
individual's right to autonomy (ACM, 2018 p. 4).
Having this as a possible outcome relies on society placing an immense amount 
of trust in technology manufacturers to act justly.
This dependence on tech could lead to widespread dissatisfaction.
Technology companies would have unchecked control over user's belongings, 
effectively placing them above the law. 
With the rise of smart devices, this control could extend to phones, appliances, cars and more. (smart device ref.)
This illustrates how act utilitarianism can lead to immoral outcomes,
as discussed by Bennett (2015, p. 60).
It's immoral to seize one's property without proper litigation/warrant.
In contrast, rule utilitarianism would establish guidelines stating that 
security technologies restricting user freedom should only be implemented 
through legal channels, such as law enforcement. 
Moreover, if no law exists to cover specific actions, the ethical imperative would be 
to create appropriate legislation before releasing such technology. 
Critics may argue that this approach could inadvertently 
allow the spread of malware and botnets, 
as malicious users wouldn't face immediate consequences 
like blacklisting without established legal procedures. 
However, the benefits of a 
comprehensive legal framework in place before deploying 
potentially restrictive technologies far outweigh these concerns. 
The potential misuse of power by technology companies is reduced to
ensure that any actions taken against users' devices are 
subject to proper legal scrutiny and oversight.
This approach aligns with the broader goal of maximising societal happiness 
by providing clear, transparent rules that protect individual autonomy 
while still allowing for necessary security measures.
As rule utilitarnism strikes a balance between innovation and 
individual rights for security technologies, it's clear that's
more effective than act utilitarianism in constructing ethical guidelines that
maximise societal happiness.

In conclusion, ethical guidelines for the computer science profession 
should prioritise societal wellbeing. 
By examining leadership challenges in data privacy and user security, 
it is evident that rule utilitarianism better serves this goal compared to act utilitarianism. 
It does so by promoting consistent and straightforward rules that are easier to implement.


## Reference List
1. GitHub (2023). GitHub Copilot · Your AI pair programmer. 
   [online] Available at: https://github.com/features/copilot
   [Accessed 18 Sep. 2024].
2. Bennet, C. (2015): "What is this thing called ethics", second edition, Routledge.
3. ACM, 2018. ACM Code of Ethics and Professional Conduct. New York: Association for Computing Machinery, Inc. DOI: 10.1145/3274591.
4. Intel. (n.d.). Intel® Software Guard Extensions (Intel® SGX). 
   [online] Available at: https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/software-guard-extensions.html
   [Accessed 18 Sep. 2024].

lecture material: Name; Lecture Topic or Number, University of NSW, 2024.
5. Lecture Slides Week 2 - Ethics in Computing, AI Ethics, and Research Integrity, University of NSW, 2024.

Value-Neutrality Thesis (VNT): “Technological artifacts do not have, have
embedded in them, or contain values. (Pitt 2000; Pitt 2014)
Pitt J. C. 2014. ““Guns Don’t Kill, People Kill”; Values in and/or around Technologies.” In The
Moral Status of Technical Artifacts, edited by Kroes P., Verbeek P. P., 89–101. Dordrecht, the
Netherlands: Springer.

Melvin Kranzberg, “Technology and History: “Kranzberg’s Laws”, Technology and Culture 27,
no. 3 (1986): 544-560.
