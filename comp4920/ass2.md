<!-- SPDX-License-Identifier: zlib-acknowledgement -->

Automated decision-making (ADM) systems powered by artificial intelligence have become increasingly prevalent in various domains, from loan approvals to hiring processes. As these systems impact people's lives, ensuring fairness, accountability, and transparency (FAT) is crucial
Present your thesis statement about the need for both technical and social causal approaches

A recidivism prediction system used in criminal justice

paragraphs into
  inputs/processing
  outputs

Achieving FAT in ADM systems requires a multifaceted approach. By combining causal and social explanations, we can create more robust, fair, and accountable systems. Causal explanations provide the technical rigor necessary for understanding and improving algorithms, while social explanations ensure that human judgment, ethics, and societal values remain central to the decision-making process. As ADM systems continue to evolve, integrating these complementary approaches will be essential for building trust and ensuring responsible AI deployment.


Where you take that discussion is up to you, but certainly you can think about both whether it is currently possible, currently not possible, possible in principle or unrealisable in principle.

## Technical (algorithmic change)
Diverse and representative data:
Ensure training data is diverse and representative of all groups the system will affect.
Regularly update and refine the dataset to reflect changing demographics or conditions.

Explainable AI (XAI) techniques:
Use interpretable machine learning models like decision trees, linear regression, or rule-based systems instead of complex neural networks when possible.


## Social (human involvement)
Appeals process:
Implement a clear and accessible process for individuals to appeal decisions made by the system.
Ensure human oversight in the appeals process.

System-Logging/Transparency reports:
Regularly publish transparency reports detailing system performance, impact assessments, and improvement efforts.

Counterfactual explanations:
Provide explanations that show how input changes would affect the decision, helping users understand what factors influence outcomes.


## References from reading
Solon Barocas, Andrew D Selbst, and Manish Raghavan. 2020. The hidden assumptions behind counterfactual explanations and principal reasons. In Proceedings of the 2020 conference on fairness, accountability, and transparency. 80–89. 

Helen Beebee. 2016. Hume and the Problem of Causation. Oxford Handbooks. 

John Brunero. 2013. Reasons as explanations. Philosophical Studies 165 (2013), 805–824. 

Alexandra Chouldechova. 2017. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big data 5, 2 (2017), 153–163. 

Julia Dressel and Hany Farid. 2018. The accuracy, fairness, and limits of predicting recidivism. Science advances 4, 1 (2018), eaao5580. 

J Fodor, Replies In B Loewer, and G Rey. 1996. Folk Psychology from the Standpoint of Conceptual Analysis. The Philosophy of Psychology (1996), 264. 

Carl Ginet. 2005. Reasons explanations of action: Causalist versus noncausalist accounts. (2005). 

Carl G Hempel. 1962. Deductive-nomological vs. statistical explanation. (1962). 

Terence Horgan and James Woodward. 2013. Folk psychology is here to stay. In Folk psychology and the philosophy of mind. Psychology Press, 144–166. 

Stephen Kearns and Daniel Star. 2008. Reasons: Explanations or evidence? Ethics 119, 1 (2008), 31–56. 

David K Lewis. 1986. Causation. (1986). Peter Lipton. 1990. Contrastive explanation. Royal Institute of Philosophy Supplements 27 (1990), 247–266. Ilkka Niiniluoto. 1981. Statistical explanation reconsidered. Synthese (1981), 437–472. 

Cynthia Rudin, Caroline Wang, and Beau Coker. 2020. The age of secrecy and unfairness in recidivism prediction. Harvard Data Science Review 2, 1 (2020), 1. 

Wesley C Salmon. 1971. Statistical explanation and statistical relevance. Vol. 69. University of Pittsburgh Pre. 

Stephen Stich and Ian Ravenscroft. 1994. What is folk psychology? Cognition 50, 1-3 (1994), 447–468. 

Ruixiang Tang, Yu-Neng Chuang, and Xia Hu. 2023. The science of detecting llm-generated texts. arXiv preprint arXiv:2303.07205 (2023). 

Bas Van Fraassen. 1988. The pragmatic theory of explanation. Theories of explanation 8 (1988), 135–155. 

Caroline Wang, Bin Han, Bhrij Patel, and Cynthia Rudin. 2023. In pursuit of interpretable, fair and accurate machine learning for criminal recidivism prediction. Journal of Quantitative Criminology 39, 2 (2023), 519–581. 



[lipton1990contrastive] - https://www.cambridge.org/core/services/aop-cambridge-core/content/view/EB3C55BBB37E6D0B2A88705EBD1F3BA5/S1358246100005130a.pdf/contrastive-explanation.pdf

[lewis1986causation] - https://academic-oup-com.wwwproxy1.library.unsw.edu.au/book/44820/chapter/383578449

[hempel1962deductive] - https://conservancy.umn.edu/items/b8ce3527-af35-44a0-be95-013a66d7af79

[stich1994folk] - https://www-sciencedirect-com.wwwproxy1.library.unsw.edu.au/science/article/pii/001002779490040X

[fodor1996folk] - can't find

[horgan2013folk] - can't find

[barocas2020hidden] - https://dl.acm.org/doi/abs/10.1145/3351095.3372830

[wang2023pursuit] - can't find

[chouldechova2017fair] - https://arxiv.org/abs/1703.00056

[brunero2013reasons] - https://link.springer.com/article/10.1007/s11098-012-9982-8
